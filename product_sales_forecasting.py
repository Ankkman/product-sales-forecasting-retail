# -*- coding: utf-8 -*-
"""product_sales_forecasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qZaKbFMet4sutsAx6NK2rlNGuM23Wl_r

# Product Sales Forecasting â€“ Retail Analytics

**Tools:** Python, Pandas, scikit-learn, Matplotlib

This notebook implements a pipeline to:
- Load and preprocess the Walmart sales CSV
- Engineer time-based and lag features
- Train simple regression models (LinearRegression, RandomForest)
- Evaluate and visualize predictions
"""

# Cell 1 - Install & Imports
import os
import gc
import numpy as np
import pandas as pd
from datetime import timedelta
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns

# Set plot defaults
plt.rcParams['figure.figsize'] = (12,5)
sns.set_style('whitegrid')

print('Libraries imported')

"""## Cell 2 - Upload

"""

# Upload helper
from google.colab import files
uploaded = files.upload()

# Set dataset path
DATA_PATH = '/content/Walmart.csv'

# Load dataset
print('Loading:', DATA_PATH)
df = pd.read_csv(DATA_PATH)
print('Rows, cols:', df.shape)
display(df.head())
display(df.dtypes)

"""## Cell 4 - Data Cleaning & Preprocessing"""

# Cell 4 - Cleaning

# Convert 'Date' to datetime and sort
df['Date'] = pd.to_datetime(df['Date'])
df = df.sort_values('Date').reset_index(drop=True)

# Handle potential missing values
df = df.dropna(subset=['Weekly_Sales'])

# Aggregate to ensure one entry per Store-Date.Removed 'Dept'.
df_agg = df.groupby(['Store', 'Date'], as_index=False)['Weekly_Sales'].sum()

# Also use the correct 'Holiday_Flag' column name here
df_agg['Holiday_Flag'] = df.groupby(['Store', 'Date'])['Holiday_Flag'].first().values

print('Aggregated shape:', df_agg.shape)
display(df_agg.head())

"""## Cell 5 - Feature Engineering

Create time features (Year, Month, Week, DayOfWeek), lag features (1,2,4 weeks), and rolling mean.
"""

# Cell 5 - Feature engineering for one product (Store-Dept)


# Isolate a single store to model. We'll pick the one with the highest total sales.

sample = df_agg.groupby(['Store'])['Weekly_Sales'].sum().nlargest(1).reset_index()
SAMPLE_STORE = int(sample['Store'])
print(f'Modeling for highest volume store -> Store: {SAMPLE_STORE}')

# We only need to filter by the store now
product_df = df_agg[df_agg['Store']==SAMPLE_STORE].copy()

# Ensure a consistent weekly frequency for the time series
product_df = product_df.set_index('Date').asfreq('W-FRI').reset_index() # Walmart data often ends on Fridays
product_df['Weekly_Sales'] = product_df['Weekly_Sales'].fillna(0)

# Use 'Holiday_Flag' and rename it to 'IsHoliday' for consistency in the model features
product_df['IsHoliday'] = product_df['Holiday_Flag'].fillna(False).astype(int)
product_df = product_df.drop('Holiday_Flag', axis=1)


# Time features
product_df['Year'] = product_df['Date'].dt.year
product_df['Month'] = product_df['Date'].dt.month
product_df['Week'] = product_df['Date'].dt.isocalendar().week.astype(int)
product_df['DayOfWeek'] = product_df['Date'].dt.dayofweek # <-- THIS IS THE NEW LINE TO ADD

# Lag features
for lag in [1, 2, 4]:
    product_df[f'lag_{lag}'] = product_df['Weekly_Sales'].shift(lag)

# Rolling mean feature
product_df['rolling_mean_4'] = product_df['Weekly_Sales'].shift(1).rolling(window=4).mean()

# Drop initial rows with NA due to lags/rolling features
product_df = product_df.dropna()
print('Feature dataframe shape:', product_df.shape)
display(product_df.head())

"""## Cell 6 - Train / Test Split

We use the last 12 weeks as the test set (approx. a 'next-quarter' demonstration).
"""

# Split the data into train and test sets
HOLDOUT_WEEKS = 12
train_df = product_df.iloc[:-HOLDOUT_WEEKS]
test_df  = product_df.iloc[-HOLDOUT_WEEKS:]

FEATURES = ['IsHoliday', 'Year', 'Month', 'Week', 'lag_1', 'lag_2', 'lag_4', 'rolling_mean_4']
TARGET = 'Weekly_Sales'

X_train, y_train = train_df[FEATURES], train_df[TARGET]
X_test, y_test = test_df[FEATURES], test_df[TARGET]

# Check shapes to confirm
print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)

"""## Cell 7 - Model 1: Linear Regression

Train a baseline Linear Regression model and evaluate with MAE and RMSE.
"""

# Model 1: Linear Regression
lr = LinearRegression()
lr.fit(X_train, y_train)
pred_lr = lr.predict(X_test)
mae_lr = mean_absolute_error(y_test, pred_lr)

# Manually calculate RMSE
rmse_lr = np.sqrt(mean_squared_error(y_test, pred_lr))

print(f'Linear Regression MAE: ${mae_lr:,.2f}')
print(f'Linear Regression RMSE: ${rmse_lr:,.2f}')

"""## Cell 8 - Model 2: Random Forest

Train a RandomForestRegressor (stronger baseline) and evaluate.
"""

# Model 2: Random Forest
rf = RandomForestRegressor(n_estimators=200, max_depth=10, min_samples_leaf=5, random_state=42, n_jobs=-1)
rf.fit(X_train, y_train)
pred_rf = rf.predict(X_test)
mae_rf = mean_absolute_error(y_test, pred_rf)

# Manually calculate RMSE
rmse_rf = np.sqrt(mean_squared_error(y_test, pred_rf))

print(f'Random Forest MAE: ${mae_rf:,.2f}')
print(f'Random Forest RMSE: ${rmse_rf:,.2f}')

"""## Cell 9 - Visualizations

Plot historical sales and Actual vs Predicted for the test period.
"""

# Visualization - Historical Sales Trend
plt.figure(figsize=(14, 5))
plt.plot(product_df['Date'], product_df['Weekly_Sales'], label='Historical Sales', color='blue')
plt.axvline(product_df['Date'].iloc[-HOLDOUT_WEEKS], color='red', linestyle='--', label='Test Start')
plt.title(f'Weekly Sales Trend - Store {SAMPLE_STORE}')
plt.xlabel('Date')
plt.ylabel('Weekly Sales ($)')
plt.legend()
plt.show()

# Actual vs Predicted (Random Forest)
plt.figure(figsize=(14, 5))
plt.plot(test_df['Date'], test_df['Weekly_Sales'].values, marker='o', label='Actual Sales', color='blue')
plt.plot(test_df['Date'], pred_rf, marker='x', linestyle='--', label='Predicted Sales (Random Forest)', color='green')
plt.title(f'Actual vs Predicted Weekly Sales - Store {SAMPLE_STORE}')
plt.xlabel('Date')
plt.ylabel('Weekly Sales ($)')
plt.legend()
plt.show()

"""## Cell 10 - Insights & Next Steps

**1. Model Performance**
- **Random Forest** outperformed **Linear Regression** on both MAE and RMSE.It captures non-linear sales patterns better.

**2. Observations from Plots**
- Sales show clear spikes during holiday periods (end of year), confirming strong seasonality in Walmart sales.
- Random Forest predictions follow the overall trend well but slightly underestimate sudden peaks.

**3. Business Implications**
- These predictions can help inventory planning by forecasting demand for the next quarter and preventing overstock or stockouts.
- Category managers could adjust promotions and pricing strategies based on the expected sales dips and peaks.
"""

# Save test predictions to a CSV for review
out = test_df[['Date']].copy()
out['actual'] = test_df[TARGET].values
out['pred_rf'] = pred_rf
out.to_csv('predictions_sample_product.csv', index=False)
print('Saved predictions_sample_product.csv')